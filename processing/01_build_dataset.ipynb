{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将h5文件读取为dict\n",
    "def hdf5_to_dict(hdf5_file):\n",
    "    hdf5_file = h5py.File(hdf5_file, \"r\")\n",
    "    def recursively_convert(h5_obj):\n",
    "        if isinstance(h5_obj, h5py.Group):\n",
    "            return {key: recursively_convert(h5_obj[key]) for key in h5_obj.keys()}\n",
    "        elif isinstance(h5_obj, h5py.Dataset):\n",
    "            return h5_obj[()]\n",
    "        else:\n",
    "            raise TypeError(\"Unsupported h5py object type\")\n",
    "    return recursively_convert(hdf5_file)\n",
    "\n",
    "# 每5帧划分为1个clip，不足5帧的clip忽略\n",
    "def get_clips_turn(picks, clip_length=5):\n",
    "    clips = []\n",
    "    reminder = len(picks) % clip_length\n",
    "    n = len(picks) - reminder\n",
    "    for i in range(0, n, clip_length):\n",
    "        clips.append(picks[i:i+clip_length])\n",
    "    return clips, reminder\n",
    "\n",
    "# 将picks划分为n段，之后针对每段跳帧取clip\n",
    "def get_clips_jump(picks, num_seg=5):\n",
    "    num_samples = len(picks) // num_seg\n",
    "    reminder = len(picks) % num_samples\n",
    "    clips = []\n",
    "    for i in range(num_samples):\n",
    "        indices = []\n",
    "        for j in range(num_seg):\n",
    "            indices.append(i+j*num_samples)\n",
    "        clips.append(picks[indices])\n",
    "    return clips, reminder\n",
    "\n",
    "# 生成sample的id\n",
    "def id_generator(dataset_name, video_name, clip_type, sample_id, remainder):\n",
    "    # example: SumMe_video_1_00000000\n",
    "    # 后八位数字的前两位表示clip的类型，00代表turn，01代表jump\n",
    "    # 中间四位代表sample的id，最后两位代表reminder，也就是有多少帧被忽略\n",
    "    # 默认sample数小于9999，reminder小于99\n",
    "    if clip_type == \"turn\":\n",
    "        clip_type = \"00\"\n",
    "    elif clip_type == \"jump\":\n",
    "        clip_type = \"01\"\n",
    "    ids = dataset_name + \"_\" + video_name + \"_\" + clip_type + sample_id.zfill(4) + remainder.zfill(2)\n",
    "    return ids\n",
    "\n",
    "# 不同的大语言模型对conversation要求不同\n",
    "def apply_conversation_template(llm_name, num_images, prompt):\n",
    "    if llm_name == \"llava-next\":\n",
    "        conversation = [\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                # 重复{\"type\": \"image\"}, num_images次\n",
    "                *[{\"type\": \"image\"} for _ in range(num_images)],\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 读取基本信息\n",
    "origin_dataset_dir = \"/root/autodl-tmp/data\"\n",
    "\n",
    "summe_h5_path = Path(origin_dataset_dir,\"SumMe\",\"summe.h5\")\n",
    "tvsum_h5_path = Path(origin_dataset_dir, \"TVSum\", \"tvsum.h5\")\n",
    "summe_json_path = Path(origin_dataset_dir, \"SumMe\", \"video_name_dict.json\")\n",
    "tvsum_json_path = Path(origin_dataset_dir, \"TVSum\", \"video_name_dict.json\")\n",
    "summe_frame_dir = Path(origin_dataset_dir, \"SumMe\", \"frames\")\n",
    "tvsum_frame_dir = Path(origin_dataset_dir, \"TVSum\", \"frames\")\n",
    "\n",
    "summe_dict = hdf5_to_dict(summe_h5_path)\n",
    "tvsum_dict = hdf5_to_dict(tvsum_h5_path)\n",
    "\n",
    "with open(summe_json_path, \"r\") as f:\n",
    "    summe_name_dict = json.load(f)\n",
    "with open(tvsum_json_path, \"r\") as f:\n",
    "    tvsum_name_dict = json.load(f)\n",
    "\n",
    "# 将summe_name_dict和tvsum_name_dict反转\n",
    "summe_name_dict_revers = {v: k for k, v in summe_name_dict.items()}\n",
    "tvsum_name_dict_revers = {v: k for k, v in tvsum_name_dict.items()}\n",
    "# summe_dict.keys()\n",
    "# tvsum_dict.keys()\n",
    "# summe_name_dict\n",
    "# tvsum_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集的一个sample示例如下\n",
    "# sample = {\n",
    "#     \"id\":\"SumMe_video_1_01000003\",\n",
    "#     \"images\": [\"path1\", \"path2\", \"path3\", \"path4\", \"path5\"],\n",
    "#     \"conversations\":{\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": [\n",
    "#           {\"type\": \"text\", \"text\": \"What is shown in this image?\"},\n",
    "#           {\"type\": \"image\"},\n",
    "#           {\"type\": \"image\"},\n",
    "#           {\"type\": \"image\"},\n",
    "#           {\"type\": \"image\"},\n",
    "#           {\"type\": \"image\"},\n",
    "#         ],\n",
    "#     },\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 生成dataset\n",
    "# context_prompt = \"If you were a law enforcement agency, how would you rate the scene described on a scale from 0 to 1, with 0 representing a standard scene and 1 denoting a scene with suspicious activities?\"\n",
    "context_prompt = \"You are a professional short film editor and director. Now you need to do some video summarization work. I will give you some frames of a short video. Please rate the frames based on their representativeness, diversity, and interest. You may need to refer to the context for rating. The rating is from 0 to 1, where 0 means not to be kept and 1 means to be kept.\"\n",
    "\n",
    "format_prompt = \"Please provide the response in the form of a Python list based on the framse and respond with just only one number for one frame in the provided list below [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] without any textual explanation. It should begin with '[' and end with ']'. Apart from the score, do not reply anything else.\"\n",
    "\n",
    "finaly_prompt = context_prompt + \" \" + format_prompt\n",
    "\n",
    "dataset_samples_turn_summe = []\n",
    "dataset_samples_jump_summe = []\n",
    "dataset_samples_turn_tvsum = []\n",
    "dataset_samples_jump_tvsum = []\n",
    "\n",
    "summe_videos = summe_dict.keys()\n",
    "tvsum_videos = tvsum_dict.keys()\n",
    "\n",
    "# 生成SumMe的dataset\n",
    "for video_name in summe_videos:\n",
    "    video_name_real = summe_name_dict_revers[video_name]\n",
    "    frames_dir = Path(summe_frame_dir, video_name_real)\n",
    "\n",
    "    video_dict = summe_dict[video_name]\n",
    "    picks = video_dict[\"picks\"]\n",
    "\n",
    "    clips_turn, remainder_turn = get_clips_turn(picks, clip_length=5)\n",
    "    clips_jump, remainder_jump = get_clips_jump(picks, num_seg=5)\n",
    "\n",
    "    for i, clip in enumerate(clips_turn):\n",
    "        sample = {}\n",
    "        sample_id = id_generator(\"SumMe\", video_name, \"turn\", str(i), str(remainder_turn))\n",
    "        sample[\"id\"] = sample_id\n",
    "        sample[\"images\"] = [str(Path(frames_dir, f\"{str(frame).zfill(6)}.jpg\")) for frame in clip]\n",
    "        sample[\"conversation\"] = apply_conversation_template(\"llava-next\", 5, finaly_prompt)\n",
    "        dataset_samples_turn_summe.append(sample)\n",
    "    \n",
    "    for i, clip in enumerate(clips_jump):\n",
    "        sample = {}\n",
    "        sample_id = id_generator(\"SumMe\", video_name, \"jump\", str(i), str(remainder_jump))\n",
    "        sample[\"id\"] = sample_id\n",
    "        sample[\"images\"] = [str(Path(frames_dir, f\"{str(frame).zfill(6)}.jpg\")) for frame in clip]\n",
    "        sample[\"conversation\"] = apply_conversation_template(\"llava-next\", 5, finaly_prompt)\n",
    "        dataset_samples_jump_summe.append(sample)\n",
    "\n",
    "# 生成TVSum的dataset\n",
    "for video_name in tvsum_videos:\n",
    "    video_name_real = tvsum_name_dict_revers[video_name]\n",
    "    frames_dir = Path(tvsum_frame_dir, video_name_real)\n",
    "\n",
    "    video_dict = tvsum_dict[video_name]\n",
    "    picks = video_dict[\"picks\"]\n",
    "\n",
    "    clips_turn, remainder_turn = get_clips_turn(picks, clip_length=5)\n",
    "    clips_jump, remainder_jump = get_clips_jump(picks, num_seg=5)\n",
    "\n",
    "    for i, clip in enumerate(clips_turn):\n",
    "        sample = {}\n",
    "        sample_id = id_generator(\"TVSum\", video_name, \"turn\", str(i), str(remainder_turn))\n",
    "        sample[\"id\"] = sample_id\n",
    "        sample[\"images\"] = [str(Path(frames_dir, f\"{str(frame).zfill(6)}.jpg\")) for frame in clip]\n",
    "        sample[\"conversation\"] = apply_conversation_template(\"llava-next\", 5, finaly_prompt)\n",
    "        dataset_samples_turn_tvsum.append(sample)\n",
    "    \n",
    "    for i, clip in enumerate(clips_jump):\n",
    "        sample = {}\n",
    "        sample_id = id_generator(\"TVSum\", video_name, \"jump\", str(i), str(remainder_jump))\n",
    "        sample[\"id\"] = sample_id\n",
    "        sample[\"images\"] = [str(Path(frames_dir, f\"{str(frame).zfill(6)}.jpg\")) for frame in clip]\n",
    "        sample[\"conversation\"] = apply_conversation_template(\"llava-next\", 5, finaly_prompt)\n",
    "        dataset_samples_jump_tvsum.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 保存dataset\n",
    "out_dir_summe = Path(\"/root/TFVSN/dataset/SumMe\")\n",
    "out_dir_tvsum = Path(\"/root/TFVSN/dataset/TVSum\")\n",
    "if not out_dir_summe.exists():\n",
    "    out_dir_summe.mkdir()\n",
    "if not out_dir_tvsum.exists():\n",
    "    out_dir_tvsum.mkdir()\n",
    "\n",
    "json_turn_summe = Path(out_dir_summe, \"summe_dataset_turn.json\")\n",
    "json_jump_summe = Path(out_dir_summe, \"summe_dataset_jump.json\")\n",
    "\n",
    "json_turn_tvsum = Path(out_dir_tvsum, \"tvsum_dataset_turn.json\")\n",
    "json_jump_tvsum = Path(out_dir_tvsum, \"tvsum_dataset_jump.json\")\n",
    "\n",
    "# 保存为json文件\n",
    "with open(json_turn_summe, \"w\") as f:\n",
    "    json.dump(dataset_samples_turn_summe, f, indent=4)\n",
    "with open(json_jump_summe, \"w\") as f:\n",
    "    json.dump(dataset_samples_jump_summe, f, indent=4)\n",
    "with open(json_turn_tvsum, \"w\") as f:\n",
    "    json.dump(dataset_samples_turn_tvsum, f, indent=4)\n",
    "with open(json_jump_tvsum, \"w\") as f:\n",
    "    json.dump(dataset_samples_jump_tvsum, f, indent=4)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
